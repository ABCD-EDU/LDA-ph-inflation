{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import operator\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Best Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>nowadays every thing seem increasing governanc...</td>\n",
       "      <td>0.872072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>disagree high</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.720877</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.055822</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>tayong magalala naniniwala isusuprise sir bbm ...</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.418144</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.540014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>ok yang nang bansa ganyan selfish fanatic blen...</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.573137</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.239034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>samasama tayong babaon</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>0.542127</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>0.041715</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Platform                                               Text   Topic 1  \\\n",
       "0  Facebook  nowadays every thing seem increasing governanc...  0.872072   \n",
       "1  Facebook                                      disagree high  0.056015   \n",
       "2  Facebook  tayong magalala naniniwala isusuprise sir bbm ...  0.010428   \n",
       "3  Facebook  ok yang nang bansa ganyan selfish fanatic blen...  0.131990   \n",
       "4  Facebook                             samasama tayong babaon  0.041692   \n",
       "\n",
       "    Topic 2   Topic 3   Topic 4   Topic 5   Topic 6  Best Topic  \n",
       "0  0.000000  0.000000  0.090702  0.000000  0.000000           1  \n",
       "1  0.056168  0.055559  0.720877  0.055559  0.055822           4  \n",
       "2  0.010424  0.010568  0.418144  0.010423  0.540014           6  \n",
       "3  0.018559  0.018721  0.573137  0.018559  0.239034           4  \n",
       "4  0.041692  0.041819  0.542127  0.290956  0.041715           4  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('./data/labelled_dataset.csv')\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(dataframe[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# import pprint\n",
    "# counts = dict(Counter(corpus))\n",
    "# duplicates = {key:value for key, value in counts.items() if value > 1}\n",
    "# pprint.pprint(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_col_names = [f\"{i}\" for i in range(len(corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs_scores(matrix:list, type:str)->dict:\n",
    "   \n",
    "   pair_scores = {}\n",
    "   res = []\n",
    "   if type=='similarity':\n",
    "      res = matrix.idxmax(axis='columns')\n",
    "   else:\n",
    "      res = matrix.idxmin(axis='columns')\n",
    "   for index, column in enumerate(res):\n",
    "      test = matrix.loc[matrix.index[index], column]\n",
    "      \n",
    "      if  test >= .9 and type==\"similarity\":\n",
    "         continue\n",
    "      elif test>=1:\n",
    "         continue\n",
    "         \n",
    "      doc1_len = len(corpus[index].split(' ')) \n",
    "      doc2_len = len(corpus[int(column)].split(' '))\n",
    "      # Exclude documents that are less than 6 and more than 30 characters\n",
    "      if doc1_len<=6 or doc2_len <=6 or doc1_len>=30 or doc2_len >=30:\n",
    "         continue\n",
    "      if f\"{column}:{index}\" not in pair_scores.keys():\n",
    "         pair_scores[f\"{index}:{column}\"] = test\n",
    "   return pair_scores\n",
    "\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))\n",
    " \n",
    "def show_sentence_pairs(pairs:list):\n",
    "   for pair in pairs:\n",
    "      doc_pair_index = pair[0].split(':')\n",
    "      doc1_idx = int(doc_pair_index[0])\n",
    "      doc2_idx = int(doc_pair_index[1])\n",
    "\n",
    "      print(f\"Sentence 1: {corpus[doc1_idx]} \\n Sentence 2: {corpus[doc2_idx]}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "# Construct the TF-IDF matrix\n",
    "tfidf_matrix = tfidf.fit_transform(corpus)\n",
    "\n",
    "\n",
    "# Generate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4686</th>\n",
       "      <th>4687</th>\n",
       "      <th>4688</th>\n",
       "      <th>4689</th>\n",
       "      <th>4690</th>\n",
       "      <th>4691</th>\n",
       "      <th>4692</th>\n",
       "      <th>4693</th>\n",
       "      <th>4694</th>\n",
       "      <th>4695</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4    5         6    7         8  \\\n",
       "0       NaN  0.0  0.000000  0.127159  0.000000  0.0  0.000000  0.0  0.000000   \n",
       "1  0.000000  NaN  0.000000  0.000000  0.000000  0.0  0.000000  0.0  0.330497   \n",
       "2  0.000000  0.0       NaN  0.000000  0.097896  0.0  0.038161  0.0  0.000000   \n",
       "3  0.127159  0.0  0.000000       NaN  0.000000  0.0  0.000000  0.0  0.000000   \n",
       "4  0.000000  0.0  0.097896  0.000000       NaN  0.0  0.000000  0.0  0.000000   \n",
       "\n",
       "     9  ...  4686  4687  4688  4689      4690  4691      4692  4693  4694  \\\n",
       "0  0.0  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0   0.0   \n",
       "1  0.0  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0   0.0   \n",
       "2  0.0  ...   0.0   0.0   0.0   0.0  0.019566   0.0  0.047418   0.0   0.0   \n",
       "3  0.0  ...   0.0   0.0   0.0   0.0  0.150336   0.0  0.000000   0.0   0.0   \n",
       "4  0.0  ...   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   0.0   0.0   \n",
       "\n",
       "   4695  \n",
       "0   0.0  \n",
       "1   0.0  \n",
       "2   0.0  \n",
       "3   0.0  \n",
       "4   0.0  \n",
       "\n",
       "[5 rows x 4696 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = pd.DataFrame(cosine_sim, index=row_col_names, columns=row_col_names )\n",
    "for i in range(len(similarity_matrix)): \n",
    "    similarity_matrix.iat[i, i] = np.nan\n",
    "similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: additional note tabloid start pilipino star nothing yet bulgar hataw title count broadsheet tabloid looking previous edition post check herehttpswwwredditcomuseryohannesburpcommentstqpcdfrontpageforbroadsheetsandtabloidthread \n",
      " Sentence 2: additional note tabloid start bulgar yesterday people newspaper included edition yet hataw title count broadsheet tabloid looking previous edition post check herehttpswwwredditcomuseryohannesburpcommentstqpcdfrontpageforbroadsheetsandtabloidthread\n",
      "Sentence 1: usually see number would say nice time nice \n",
      " Sentence 2: usually would reply nice see isnt nice\n",
      "Sentence 1: happy kaming minion importante nakabalik junior malacaang tahanan \n",
      " Sentence 2: importante happy majority filipino people nakabalik marcos tahanan\n",
      "Sentence 1: hahahaha sure kang government edi wala silang kurakot \n",
      " Sentence 2: ayaw kurakot sinasabi edi wala silang kurakot gustong pang mangyari\n",
      "Sentence 1: mahal mg kuryente niyo ate baka nakikikabit dyan mahal ganun kamahal kunsumo ref \n",
      " Sentence 2: mahal kuryente ate baka maraming nakikikabit diyan\n",
      "Sentence 1: nobody complains kilo tomato kilo banana expensive kilo pork people already diabetis high blood fat afugh \n",
      " Sentence 2: pbbm n kilo bigas n kilo n\n",
      "Sentence 1: want retire cheap rd world country expect rd world quality life cant cake eat \n",
      " Sentence 2: rd world country price good st world rate high\n",
      "Sentence 1: mahal bigas middle man naalis middle man possible bumaba price \n",
      " Sentence 2: need magsasaka tatanggalin middle man middle man nagpapahirap magsasaka\n",
      "Sentence 1: people government smart remittance ofw helping economy \n",
      " Sentence 2: government stop claiming economy relies ofw remittance\n",
      "Sentence 1: political analyst stock analyst agricultural expert hahaha \n",
      " Sentence 2: ekonomista historian analyst crypto expert lawyer political expert marketing expert aba talino ah\n",
      "Sentence 1: gumagamit ac pm arawaraw ref ibang appliance ngunit k kuryente nagka bill k siguro init \n",
      " Sentence 2: grabe bill kuryente ref ac hr day gana tv ibang appliance nasa k mothly bill\n",
      "Sentence 1: think worse st world country bec holiday season many want spend good scarce due supply chain issue rd world spending much mangeable \n",
      " Sentence 2: rd world country price good st world rate high\n",
      "Sentence 1: june year date skyrocketed month june maybe war ukraine \n",
      " Sentence 2: understanding mataas month june specific month unlike consecutive month june\n",
      "Sentence 1: sweldo man tumaas tumaas utang banda shemay \n",
      " Sentence 2: ok sanang tumaas sana tumaas sweldo trabahante\n",
      "Sentence 1: implasyonmali daw president bbmantayin p kilo bigas \n",
      " Sentence 2: pbbm n kilo bigas n kilo n\n",
      "Sentence 1: hi gossip incoming psei rebalancing like example rumor secbdmcscc another question psei always stock include deserving company like dmc areit \n",
      " Sentence 2: hi tsismis regarding psei rebalancing dmc scc\n",
      "Sentence 1: parang pwede e kakaupo palang bbm haha \n",
      " Sentence 2: pangungunahan bbm kakaupo palang month president bbm tapos dami kuda anti\n",
      "Sentence 1: ibang bansa ok tumaas presyo malaki sweldo pilipinas unity \n",
      " Sentence 2: ok sanang tumaas sana tumaas sweldo trabahante\n",
      "Sentence 1: filipino inflated ego many would rather play deeper mud admit wrong \n",
      " Sentence 2: would rather feed ego rather admitting wrong\n",
      "Sentence 1: wala kayang ok sustentuhan pagwaldas pera dayunyor tiis tiis basta unity \n",
      " Sentence 2: sorry tyo tiis tiis affectected happy proud\n"
     ]
    }
   ],
   "source": [
    "pair_scores = get_pairs_scores(similarity_matrix, \"similarity\")\n",
    "topPairs = dict(sorted(pair_scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "topN_pairs = take(20, topPairs.items())\n",
    "show_sentence_pairs(topN_pairs)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4686</th>\n",
       "      <th>4687</th>\n",
       "      <th>4688</th>\n",
       "      <th>4689</th>\n",
       "      <th>4690</th>\n",
       "      <th>4691</th>\n",
       "      <th>4692</th>\n",
       "      <th>4693</th>\n",
       "      <th>4694</th>\n",
       "      <th>4695</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961839</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.872841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.849664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4696 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4    5         6    7         8  \\\n",
       "0       NaN  1.0  1.000000  0.872841  1.000000  1.0  1.000000  1.0  1.000000   \n",
       "1  1.000000  NaN  1.000000  1.000000  1.000000  1.0  1.000000  1.0  0.669503   \n",
       "2  1.000000  1.0       NaN  1.000000  0.902104  1.0  0.961839  1.0  1.000000   \n",
       "3  0.872841  1.0  1.000000       NaN  1.000000  1.0  1.000000  1.0  1.000000   \n",
       "4  1.000000  1.0  0.902104  1.000000       NaN  1.0  1.000000  1.0  1.000000   \n",
       "\n",
       "     9  ...  4686  4687  4688  4689      4690  4691      4692  4693  4694  \\\n",
       "0  1.0  ...   1.0   1.0   1.0   1.0  1.000000   1.0  1.000000   1.0   1.0   \n",
       "1  1.0  ...   1.0   1.0   1.0   1.0  1.000000   1.0  1.000000   1.0   1.0   \n",
       "2  1.0  ...   1.0   1.0   1.0   1.0  0.980434   1.0  0.952582   1.0   1.0   \n",
       "3  1.0  ...   1.0   1.0   1.0   1.0  0.849664   1.0  1.000000   1.0   1.0   \n",
       "4  1.0  ...   1.0   1.0   1.0   1.0  1.000000   1.0  1.000000   1.0   1.0   \n",
       "\n",
       "   4695  \n",
       "0   1.0  \n",
       "1   1.0  \n",
       "2   1.0  \n",
       "3   1.0  \n",
       "4   1.0  \n",
       "\n",
       "[5 rows x 4696 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate cosine similarity\n",
    "cosine_distance = cosine_distances(tfidf_matrix, tfidf_matrix)\n",
    "distance_matrix = pd.DataFrame(cosine_distance, index=row_col_names, columns=row_col_names )\n",
    "for i in range(len(distance_matrix)): \n",
    "    distance_matrix.iat[i, i] = np.nan\n",
    "distance_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: fish free tuna sound friendlier tuna business opposed unfish could construed attack core business \n",
      " Sentence 2: government business enterprise food rice part national security\n",
      "Sentence 1: haha true kc tatalino ngaw ngaw ngaw ngaw hahah nmn magets year date basic jusmi \n",
      " Sentence 2: research nyang oras alam month date year date\n",
      "Sentence 1: right confront dictator junior daughtertes supporter shenanigan pulled last election call hypocrisy doubt theyll get fired political belief dont interfere work ethic performance \n",
      " Sentence 2: marcoss supporter dont even mean let alone economics work\n",
      "Sentence 1: alam gaano karaming effort mabibigay pagtitipid pagtitiis nagsisipag parang nararating bwisit \n",
      " Sentence 2: grabe dami anak tuwing nakikita naiirita bwisit\n",
      "Sentence 1: discriminatory vaccine passport mandate utter disgrace comply \n",
      " Sentence 2: tell bf eat dick lmao umno najib fucking disgrace\n",
      "Sentence 1: check fmetf first metro etf work cheaper alternative term fee also go sun life convenient youps study getting risk involved fee expectation etc jumping \n",
      " Sentence 2: salamat sharing siomai king promo k k franchise fee\n",
      "Sentence 1: really thought could barge well established market duopoly strong arm becoming third member duterte two telecom giant strangle divy remains \n",
      " Sentence 2: one best cabinet member president duterte salute man\n",
      "Sentence 1: got scammed lenilugaw youre going get scammed butter lmao \n",
      " Sentence 2: gon lead country got highi trying curb got highour debt level still messed know whycause got highbecause got highbecause got high\n",
      "Sentence 1: venus project prated version tuluyang makakapaglunas debt socioeconomicstructural inefficiency \n",
      " Sentence 2: dont forget caused government debt global caused global debt quadrillion raw debt\n",
      "Sentence 1: batong narrator nato kagana gana kalatoy latoy \n",
      " Sentence 2: paki mention oras wala nako gana manood balita\n",
      "Sentence 1: yup confirm chat couple friend staggering economy ph mess today previous admin yet still blame dilawans anlungkot tignan ganoon katindi pagiging panatiko \n",
      " Sentence 2: compare previous admin war last time uncontrollable\n",
      "Sentence 1: know theyre gon get chewed question asked opposite side many kakampinks cautious voicing side unpredictable behavior even action marcosexuals \n",
      " Sentence 2: saving rent transportation expense working home made side gig possible side gig wonder saving investment\n",
      "Sentence 1: would advise check top expensive thing spend improve make sense trying save penny ignoring one cost thousandsfor example rent relocation utility solar water purifier cheaper transpo rideshare bike \n",
      " Sentence 2: well safe rule anytime whether recession boom time always spend lower salary save save save\n",
      "Sentence 1: make sound like people dont throw thrash window saw lot thrash side freeway visited california justifying putting thing perspectiveim hap chan awful \n",
      " Sentence 2: doesnt make sense dont throw claim lab rat theyre use experiment seriously want yo make sound smart try\n",
      "Sentence 1: forget sugar phillipines need discover wholemeal bread \n",
      " Sentence 2: dont forget also order solve rate target rate\n",
      "Sentence 1: importing lot foodincluding riceto feed people really difference driving v vietnam \n",
      " Sentence 2: look golden spade big enough feed ego\n",
      "Sentence 1: magulo f pinsan fav sonyour future president \n",
      " Sentence 2: world wide inflationkahit pang presidente makakaiwaspasalamat natulad bankrupt gaya sri lanka magulo buhay\n",
      "Sentence 1: k palengke allotment weekly pre pandemic k ngayonyung monthly allotment grocery k dati k \n",
      " Sentence 2: ata diba palagi sinasabi dati dati dati dati lol parang edad dati yr old yr old kana basic sample maintindihan tumataas halaga take note pinas kundi buong mundo\n",
      "Sentence 1: httpsacesubidonetphinflationcalculatorwatch friend mine mass market limited edition rolex seiko watch adamant buy watch investmenti pointed way product appreciate value scarcity involved desire scarcity \n",
      " Sentence 2: luxury watch like rolex also hit dip based report httpswwwbloombergcomopinionarticlescryptostockmeltdownhitsrolexpatekphilippeaudemarspiguetwatches\n",
      "Sentence 1: create maraming trabahodapat trabaho ibigay taohindi ayudapag meron pong puede pang magtrabaho pamilya trabaho ibigay okay pong bigyan ayuda yong puedeng magtrabahoat pababain presyo bilihinyong mabibili murang halaga \n",
      " Sentence 2: dami kasing anak problema pagtaas presyo problema kalibugan pong asawa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pair_scores = get_pairs_scores(distance_matrix, \"distance\")\n",
    "topPairs = dict(sorted(pair_scores.items(), key=operator.itemgetter(1),reverse=True))\n",
    "topN_pairs = take(20, topPairs.items())\n",
    "show_sentence_pairs(topN_pairs)      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data-mining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d5d9dcc67efa92ef875b9aa025d58eddcbf3c78cff45ba05987629fa8b55ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
