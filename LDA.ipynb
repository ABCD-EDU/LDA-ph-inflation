{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "# for text preprocessing\n",
    "import re\n",
    "# import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "# import numpy for matrix operation\n",
    "import numpy as np\n",
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "dataframe = pd.read_csv(\"./data/preprocessed.csv\")\n",
    "# clean_corpus = dataframe[\"preprocessed\"]\n",
    "# clean_corpus = [x.strip('][').split(', ') for x in dataframe[\"preprocessed\"]]\n",
    "# string to list\n",
    "clean_corpus = [ast.literal_eval(x) for x in dataframe[\"preprocessed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where every unique term is assigned an index.\n",
    "dict_ = corpora.Dictionary(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using the dictionary\n",
    "doc_term_matrix = [dict_.doc2bow(i) for i in clean_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.010*\"price\" + 0.008*\"country\" + 0.007*\"rate\" + 0.007*\"like\" + 0.006*\"people\"'), (1, '0.009*\"golden\" + 0.009*\"peso\" + 0.007*\"haha\" + 0.006*\"daw\" + 0.005*\"bigas\"'), (2, '0.007*\"dont\" + 0.007*\"economy\" + 0.006*\"one\" + 0.006*\"people\" + 0.005*\"like\"'), (3, '0.012*\"wala\" + 0.010*\"bilihin\" + 0.008*\"sana\" + 0.007*\"gobyerno\" + 0.006*\"tapos\"'), (4, '0.011*\"share\" + 0.008*\"mb\" + 0.007*\"company\" + 0.007*\"ipo\" + 0.006*\"billion\"'), (5, '0.011*\"k\" + 0.006*\"covid\" + 0.005*\"kuryente\" + 0.005*\"mahal\" + 0.005*\"pbbm\"')]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to retrain LDAModel\n",
    "# %%script false\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix.\n",
    "ldamodel = Lda(corpus=doc_term_matrix, num_topics=6, id2word = dict_, passes=20, random_state=20, eval_every=None)\n",
    "\n",
    "# Prints the topics with the indexes: 0,1,2 :\n",
    "ldamodel.print_topics()\n",
    "# we need to manually check whethere the topics are different from one another or not\n",
    "print(ldamodel.print_topics(num_topics=6, num_words=5))\n",
    "\n",
    "# num_topics mean: how many topics want to extract\n",
    "# num_words: the number of words that want per topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment to prevent loading the pretrained model\n",
    "# %%script false\n",
    "\n",
    "import pickle\n",
    "\n",
    "ldamodel = None\n",
    "with open('./out/lda_model.pkl', 'rb') as f:\n",
    "    ldamodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6673389727540426"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "coherence_model = CoherenceModel(model=ldamodel, texts=clean_corpus, dictionary=dict_, coherence=\"c_v\")\n",
    "\n",
    "coherence_model.get_coherence() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.19287994883112\n",
      "72610.99637295035\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Gensim’s perplexity value is in logarithmic form. To compare with sklearn’s perplexity value np.exp(-1 *gensim.log_perplexity) is used\n",
    "\n",
    "print(ldamodel.log_perplexity(doc_term_matrix ))\n",
    "print(np.exp(-1 * ldamodel.log_perplexity(doc_term_matrix )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_rows = []\n",
    "\n",
    "for index,doc_in_words in enumerate(clean_corpus):\n",
    "    doc_in_words_as_string = ' '.join(doc_in_words)\n",
    "    row_vals = [dataframe.loc[index,'platform'], doc_in_words_as_string]+list(np.zeros(6))\n",
    "    doc_topics = ldamodel.get_document_topics(dict_.doc2bow(doc_in_words))\n",
    "    for doc_topic in doc_topics:\n",
    "        row_vals[doc_topic[0]+2] = doc_topic[1]\n",
    "    index_of_best_topic = np.argmax(row_vals[2:])\n",
    "    row_vals.append(index_of_best_topic+1)\n",
    "    all_rows.append(row_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Best Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>nowadays every thing seem increasing governanc...</td>\n",
       "      <td>0.872072</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>disagree high</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.056168</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.720877</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.055822</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>tayong magalala naniniwala isusuprise sir bbm ...</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.418144</td>\n",
       "      <td>0.010423</td>\n",
       "      <td>0.540014</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>ok yang nang bansa ganyan selfish fanatic blen...</td>\n",
       "      <td>0.131990</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.573137</td>\n",
       "      <td>0.018559</td>\n",
       "      <td>0.239034</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>samasama tayong babaon</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>0.041819</td>\n",
       "      <td>0.542127</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>0.041715</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>mukhang nakashabu</td>\n",
       "      <td>0.055780</td>\n",
       "      <td>0.055779</td>\n",
       "      <td>0.055781</td>\n",
       "      <td>0.055782</td>\n",
       "      <td>0.390796</td>\n",
       "      <td>0.386081</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>bbm mixed confusing economic term</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.185259</td>\n",
       "      <td>0.028051</td>\n",
       "      <td>0.028246</td>\n",
       "      <td>0.193463</td>\n",
       "      <td>0.536937</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>mrutal utal</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.055652</td>\n",
       "      <td>0.055652</td>\n",
       "      <td>0.388764</td>\n",
       "      <td>0.388631</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>leni lutang</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.055618</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>0.388053</td>\n",
       "      <td>0.055620</td>\n",
       "      <td>0.389472</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>knowns puro kuda wala maitutulong magtrabaho k...</td>\n",
       "      <td>0.269412</td>\n",
       "      <td>0.219258</td>\n",
       "      <td>0.248013</td>\n",
       "      <td>0.201738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4696 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Platform                                               Text   Topic 1  \\\n",
       "0     Facebook  nowadays every thing seem increasing governanc...  0.872072   \n",
       "1     Facebook                                      disagree high  0.056015   \n",
       "2     Facebook  tayong magalala naniniwala isusuprise sir bbm ...  0.010428   \n",
       "3     Facebook  ok yang nang bansa ganyan selfish fanatic blen...  0.131990   \n",
       "4     Facebook                             samasama tayong babaon  0.041692   \n",
       "...        ...                                                ...       ...   \n",
       "4691   Youtube                                  mukhang nakashabu  0.055780   \n",
       "4692   Youtube                  bbm mixed confusing economic term  0.028045   \n",
       "4693   Youtube                                        mrutal utal  0.055651   \n",
       "4694   Youtube                                        leni lutang  0.055619   \n",
       "4695   Youtube  knowns puro kuda wala maitutulong magtrabaho k...  0.269412   \n",
       "\n",
       "       Topic 2   Topic 3   Topic 4   Topic 5   Topic 6  Best Topic  \n",
       "0     0.000000  0.000000  0.090702  0.000000  0.000000           1  \n",
       "1     0.056168  0.055559  0.720877  0.055559  0.055822           4  \n",
       "2     0.010424  0.010568  0.418144  0.010423  0.540014           6  \n",
       "3     0.018559  0.018721  0.573137  0.018559  0.239034           4  \n",
       "4     0.041692  0.041819  0.542127  0.290956  0.041715           4  \n",
       "...        ...       ...       ...       ...       ...         ...  \n",
       "4691  0.055779  0.055781  0.055782  0.390796  0.386081           5  \n",
       "4692  0.185259  0.028051  0.028246  0.193463  0.536937           6  \n",
       "4693  0.055651  0.055652  0.055652  0.388764  0.388631           5  \n",
       "4694  0.055618  0.055619  0.388053  0.055620  0.389472           6  \n",
       "4695  0.219258  0.248013  0.201738  0.000000  0.053552           1  \n",
       "\n",
       "[4696 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labelled_dataset = pd.DataFrame(all_rows, columns=[\"Platform\",\"Text\"]+[f\"Topic {i+1}\" for i in range(6)]+[\"Best Topic\"])\n",
    "labelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset.to_csv(\"./data/labelled_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump model\n",
    "pickle.dump(ldamodel, open('./out/lda_model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
