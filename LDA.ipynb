{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "# for text preprocessing\n",
    "import re\n",
    "# import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "# import numpy for matrix operation\n",
    "import numpy as np\n",
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora  \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "dataframe = pd.read_csv(\"./data/preprocessed.csv\")\n",
    "clean_corpus = [ast.literal_eval(x) for x in dataframe[\"preprocessed\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where every unique term is assigned an index.\n",
    "dict_ = corpora.Dictionary(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using the dictionary\n",
    "doc_term_matrix = [dict_.doc2bow(i) for i in clean_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.010*\"price\" + 0.008*\"country\" + 0.007*\"rate\" + 0.007*\"like\" + 0.006*\"people\"'), (1, '0.009*\"golden\" + 0.009*\"peso\" + 0.007*\"haha\" + 0.006*\"daw\" + 0.005*\"bigas\"'), (2, '0.007*\"dont\" + 0.007*\"economy\" + 0.006*\"one\" + 0.006*\"people\" + 0.005*\"like\"'), (3, '0.012*\"wala\" + 0.010*\"bilihin\" + 0.008*\"sana\" + 0.007*\"gobyerno\" + 0.006*\"tapos\"'), (4, '0.011*\"share\" + 0.008*\"mb\" + 0.007*\"company\" + 0.007*\"ipo\" + 0.006*\"billion\"'), (5, '0.011*\"k\" + 0.006*\"covid\" + 0.005*\"kuryente\" + 0.005*\"mahal\" + 0.005*\"pbbm\"')]\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to retrain LDAModel\n",
    "# %%script false\n",
    "# Creating the object for LDA model using gensim library\n",
    "\n",
    "n_topics = 6\n",
    "\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix.\n",
    "ldamodel = Lda(corpus=doc_term_matrix, num_topics=n_topics , id2word = dict_, passes=20, random_state=20, eval_every=None)\n",
    "\n",
    "# Prints the topics with the indexes: 0,1,2 :\n",
    "ldamodel.print_topics()\n",
    "# we need to manually check whethere the topics are different from one another or not\n",
    "print(ldamodel.print_topics(num_topics=n_topics , num_words=5))\n",
    "\n",
    "# num_topics mean: how many topics want to extract\n",
    "# num_words: the number of words that want per topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_member(a, b):\n",
    "    a_set = set(a)\n",
    "    b_set = set(b)\n",
    "    # print(a==b)\n",
    "    if (a_set & b_set):\n",
    "        return (a_set & b_set)\n",
    "    else:\n",
    "        return \"No common elements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ldamodel.show_topics(num_words=100)\n",
    "\n",
    "twords={}\n",
    "for topic,words in x:\n",
    "    words_in_string =re.sub('[^A-Za-z ]+', '', words)\n",
    "    words_in_list =[word for word in words_in_string.split(' ') if word != '' ] \n",
    "    twords[topic] = words_in_list\n",
    "   #  print(words_in_list)\n",
    "    \n",
    "# print(twords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ = {}\n",
    "for i,words_in_list1 in twords.items():\n",
    "   for j,words_in_list2 in twords.items():\n",
    "      \n",
    "      count_[f\"{i}:{j}\"] = True\n",
    "      if  f\"{j}:{i}\" in count_.keys(): \n",
    "         continue\n",
    "      if i==j :\n",
    "         continue\n",
    "      # print(f'{i}:{j}: Common Member {common_member(words_in_list1, words_in_list2)}')\n",
    "      # print(words_in_list1==words_in_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comment to prevent loading the pretrained model\n",
    "# # %%script false\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# ldamodel = None\n",
    "# with open('./out/lda_model.pkl', 'rb') as f:\n",
    "#     ldamodel = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import CoherenceModel\n",
    "\n",
    "# coherence_model = CoherenceModel(model=ldamodel, texts=clean_corpus, dictionary=dict_, coherence=\"c_v\")\n",
    "\n",
    "# coherence_model.get_coherence() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.697503900538264\n",
      "5987.938142420413\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Gensim’s perplexity value is in logarithmic form. To compare with sklearn’s perplexity value np.exp(-1 *gensim.log_perplexity) is used\n",
    "\n",
    "print(ldamodel.log_perplexity(doc_term_matrix ))\n",
    "print(np.exp(-1 * ldamodel.log_perplexity(doc_term_matrix )))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_rows = []\n",
    "\n",
    "\n",
    "\n",
    "for index,doc_in_words in enumerate(clean_corpus):\n",
    "    doc_in_words_as_string = ' '.join(doc_in_words)\n",
    "    row_vals = [dataframe.loc[index,'platform'], dataframe.loc[index, 'raw'] ,doc_in_words_as_string]+list(np.zeros(n_topics))\n",
    "    doc_topics = ldamodel.get_document_topics(dict_.doc2bow(doc_in_words))\n",
    "    \n",
    "    for doc_topic in doc_topics:\n",
    "        row_vals[doc_topic[0]+3] = doc_topic[1]\n",
    "    index_of_best_topic = np.argmax(row_vals[3:])\n",
    "    \n",
    "    row_vals.append(index_of_best_topic+1)\n",
    "    all_rows.append(row_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Arian\\.conda\\envs\\data-mining\\lib\\site-packages\\pyLDAvis\\_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "%matplotlib inline\n",
    "\n",
    "gensimvis_dict = gensimvis.prepare(ldamodel ,doc_term_matrix , dict_).to_dict()\n",
    "\n",
    "\n",
    "# gensimvis_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_.token2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bless</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bless</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>control</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>control</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>country</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22295</th>\n",
       "      <td>mrutal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22296</th>\n",
       "      <td>utal</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22297</th>\n",
       "      <td>aaralan</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22298</th>\n",
       "      <td>kakaumpisa</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22299</th>\n",
       "      <td>knowns</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Term  Topic  Frequency\n",
       "0           bless      4   0.000899\n",
       "1           bless      6   0.000845\n",
       "2         control      1   0.001527\n",
       "3         control      3   0.000254\n",
       "4         country      1   0.007802\n",
       "...           ...    ...        ...\n",
       "22295      mrutal      2   0.000311\n",
       "22296        utal      2   0.000311\n",
       "22297     aaralan      4   0.000197\n",
       "22298  kakaumpisa      4   0.000197\n",
       "22299      knowns      4   0.000197\n",
       "\n",
       "[22300 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_to_topic_df = pd.DataFrame(\n",
    "     columns=[\"Term\", \"Topic\",\"Frequency\"])\n",
    "for term, id in dict_.token2id.items():\n",
    "   test = ldamodel.get_term_topics(id, minimum_probability=0.00001)\n",
    "   for i in test:\n",
    "      term_to_topic_df.loc[len(term_to_topic_df )] =[term, int(i[0])+1,i[1]]\n",
    "      \n",
    "\n",
    "term_to_topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_to_topic_df.to_csv('./data/term_to_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term_to_topic_df = pd.DataFrame(\n",
    "#      columns=[\"Term\", \"Topic\",\"Frequency\"])\n",
    "\n",
    "# topic_designations = gensimvis_dict['token.table']['Topic']\n",
    "# terms = gensimvis_dict['token.table']['Term']\n",
    "# term_frequency = gensimvis_dict['token.table']['Freq']\n",
    "# term_to_topic_designation_dict = {}\n",
    "# for n_topic,term,frequency in zip(topic_designations, terms, term_frequency):\n",
    "#    # term_to_topic_designation_dict[term] = [frequency, n_topic]\n",
    "#    # if term in term_to_topic_designation_dict.keys():\n",
    "#    #    if frequency> term_to_topic_designation_dict[term][0]:\n",
    "#    #       term_to_topic_designation_dict[term][1] = n_topic\n",
    "#    #    else: \n",
    "#    #       pass\n",
    "#    to_append = [term, n_topic, frequency]\n",
    "#    term_to_topic_df.loc[len(term_to_topic_df )] = to_append\n",
    "\n",
    "# term_to_topic_df.to_csv('./data/term_to_topic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22300, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_to_topic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Text</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Best Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Why nowadays every thing  seem to be increasin...</td>\n",
       "      <td>nowadays every thing seem increasing governanc...</td>\n",
       "      <td>0.473528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124946</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>I will have to disagree.. we’re not that high!!</td>\n",
       "      <td>disagree high</td>\n",
       "      <td>0.056182</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.055583</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Wag po tayong mag-alala. Naniniwala po ako, is...</td>\n",
       "      <td>tayong magalala naniniwala isusuprise sir bbm ...</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.139007</td>\n",
       "      <td>0.314224</td>\n",
       "      <td>0.247254</td>\n",
       "      <td>0.010458</td>\n",
       "      <td>0.278587</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Ok lang yang lahat naman nang bansa ganyan. Sa...</td>\n",
       "      <td>ok yang nang bansa ganyan selfish fanatic blen...</td>\n",
       "      <td>0.018524</td>\n",
       "      <td>0.018563</td>\n",
       "      <td>0.018567</td>\n",
       "      <td>0.618591</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>0.307228</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Sama-sama tayong BABAON muli.</td>\n",
       "      <td>samasama tayong babaon</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>0.791544</td>\n",
       "      <td>0.041687</td>\n",
       "      <td>0.041706</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>mukhang nakashabu</td>\n",
       "      <td>mukhang nakashabu</td>\n",
       "      <td>0.055576</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.055576</td>\n",
       "      <td>0.055722</td>\n",
       "      <td>0.055576</td>\n",
       "      <td>0.721973</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>Bbm is mixed up and confusing on economic terms</td>\n",
       "      <td>bbm mixed confusing economic term</td>\n",
       "      <td>0.386169</td>\n",
       "      <td>0.027944</td>\n",
       "      <td>0.502167</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.027846</td>\n",
       "      <td>0.027975</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>Mr.utal utal</td>\n",
       "      <td>mrutal utal</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.722116</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>0.055577</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>Kung Si Leni Pa Yan \\r\\n\\r\\nLutang Na Tayo</td>\n",
       "      <td>leni lutang</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.721804</td>\n",
       "      <td>0.055711</td>\n",
       "      <td>0.055653</td>\n",
       "      <td>0.055558</td>\n",
       "      <td>0.055715</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>Youtube</td>\n",
       "      <td>he knowns what to do wag kayo puro kuda wala n...</td>\n",
       "      <td>knowns puro kuda wala maitutulong magtrabaho k...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059212</td>\n",
       "      <td>0.160837</td>\n",
       "      <td>0.756102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4696 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Platform                                                Raw  \\\n",
       "0     Facebook  Why nowadays every thing  seem to be increasin...   \n",
       "1     Facebook    I will have to disagree.. we’re not that high!!   \n",
       "2     Facebook  Wag po tayong mag-alala. Naniniwala po ako, is...   \n",
       "3     Facebook  Ok lang yang lahat naman nang bansa ganyan. Sa...   \n",
       "4     Facebook                      Sama-sama tayong BABAON muli.   \n",
       "...        ...                                                ...   \n",
       "4691   Youtube                                  mukhang nakashabu   \n",
       "4692   Youtube    Bbm is mixed up and confusing on economic terms   \n",
       "4693   Youtube                                       Mr.utal utal   \n",
       "4694   Youtube        Kung Si Leni Pa Yan \\r\\n\\r\\nLutang Na Tayo    \n",
       "4695   Youtube  he knowns what to do wag kayo puro kuda wala n...   \n",
       "\n",
       "                                                   Text   Topic 1   Topic 2  \\\n",
       "0     nowadays every thing seem increasing governanc...  0.473528  0.000000   \n",
       "1                                         disagree high  0.056182  0.055559   \n",
       "2     tayong magalala naniniwala isusuprise sir bbm ...  0.010470  0.139007   \n",
       "3     ok yang nang bansa ganyan selfish fanatic blen...  0.018524  0.018563   \n",
       "4                                samasama tayong babaon  0.041687  0.041688   \n",
       "...                                                 ...       ...       ...   \n",
       "4691                                  mukhang nakashabu  0.055576  0.055577   \n",
       "4692                  bbm mixed confusing economic term  0.386169  0.027944   \n",
       "4693                                        mrutal utal  0.055577  0.722116   \n",
       "4694                                        leni lutang  0.055558  0.721804   \n",
       "4695  knowns puro kuda wala maitutulong magtrabaho k...  0.000000  0.059212   \n",
       "\n",
       "       Topic 3   Topic 4   Topic 5   Topic 6  Best Topic  \n",
       "0     0.373507  0.000000  0.000000  0.124946           1  \n",
       "1     0.056438  0.720307  0.055583  0.055932           4  \n",
       "2     0.314224  0.247254  0.010458  0.278587           3  \n",
       "3     0.018567  0.618591  0.018527  0.307228           4  \n",
       "4     0.041687  0.791544  0.041687  0.041706           4  \n",
       "...        ...       ...       ...       ...         ...  \n",
       "4691  0.055576  0.055722  0.055576  0.721973           6  \n",
       "4692  0.502167  0.027899  0.027846  0.027975           3  \n",
       "4693  0.055577  0.055577  0.055577  0.055577           2  \n",
       "4694  0.055711  0.055653  0.055558  0.055715           2  \n",
       "4695  0.160837  0.756102  0.000000  0.000000           4  \n",
       "\n",
       "[4696 rows x 10 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "labelled_dataset = pd.DataFrame(all_rows, columns=[\"Platform\",\"Raw\",\"Text\"]+[f\"Topic {i+1}\" for i in range(n_topics)]+[\"Best Topic\"])\n",
    "labelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_dataset.to_csv(\"./data/labelled_dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump model\n",
    "# pickle.dump(ldamodel, open('./out/lda_model.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('data-mining')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d5d9dcc67efa92ef875b9aa025d58eddcbf3c78cff45ba05987629fa8b55ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
